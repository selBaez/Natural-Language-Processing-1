{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This exercise is meant to help you get familiar with some language data. \n",
    "\n",
    "The corpus used is the **Penn Treebank**, which is a collection of data from the newspaper \n",
    "The Wall Street Journal. The exercise will not take more than a few lines of code; the idea is to examine the data, and notice interesting properties.\n",
    "\n",
    "## Required software\n",
    "\n",
    "### Easy installation\n",
    "\n",
    "The easiest way to get the required software is to install Anaconda. See https://www.continuum.io/downloads . It contains all required packages, including python and jupyter. You can choose python 2.7 or 3.5.\n",
    "\n",
    "### Manual installation\n",
    "\n",
    "Make sure that you have `numpy` and `matplotlib` installed. If you don't, you can use e.g. `pip install <package> --user` (python2) or `pip3 install <package> --user` (python3).\n",
    "\n",
    "## Submission\n",
    "We will grade your assignments with pass/fail/good, so don't forget to hand them in! \n",
    "Choose `File->Download as->HTML` and check if the HTML-file contains all your answers. You can work and submit in pairs. Please e-mail your TA with `\"[NLP1] Assignment 1\"` as the subject. \n",
    "**The deadline for submission is Sunday 6 nov 23:59.**\n",
    "\n",
    "## Start the notebook\n",
    "\n",
    "Start a terminal, and `cd` into the directory where you saved the notebook. Then type `jupyter notebook`. Your web browser will open."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided with a corpus containing words and their Part-of-speech tags in the format is\n",
    "**word|POS** (one sentence per line) (file name : **sec02-21.gold.tagged**). This data is extracted from Sections 02-21 from the Penn Treebank: these sections are most commonly used for training statistical models (like POS-taggers and parsers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) What are the total number of words (tokens) in this corpus? \n",
    "What is the number of distinct word types?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n_sentences = 0\n",
    "clear_sentences = [] # We need the \"clean\" sentences in order to measure probabilities per sentence\n",
    "words = []\n",
    "pos = []\n",
    "\n",
    "with open('sec02-21.gold.tagged', 'r') as f:\n",
    "    for sentence in f:\n",
    "        n_sentences += 1\n",
    "        temp = sentence.split()\n",
    "        words += (temp[i].split('|')[0] for i in range(len(temp)))\n",
    "        pos += (temp[i].split('|')[1] for i in range(len(temp)))\n",
    "\n",
    "\n",
    "clear_text = (' ').join(words)\n",
    "\n",
    "clear_sentences += clear_text.split(' . ')\n",
    "\n",
    "print clear_sentences[1]\n",
    "\n",
    "distinct_words = set(words)\n",
    "distinct_pos = set(pos)\n",
    "\n",
    "print \"Number of sentences: \", n_sentences\n",
    "print \"Number of words: \", len(words)\n",
    "print \"Number of distinct words: \", len(distinct_words)\n",
    "print \"Number of distinct pos: \", len(distinct_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Plot a graph of word frequency versus rank of a word, in this corpus. Does this corpus obey Zipfâ€™s law?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "corpus_words = Counter(words)\n",
    "# My laptop sucks and cannot plot for all words, try removing the 100 and run cell again Selaki :)\n",
    "# I also think that it might be impossible to plot all with barchart... maybe we can try histogram!\n",
    "sorted_corpus_words = corpus_words.most_common(80)\n",
    "\n",
    "\n",
    "tokens = [x[0] for x in sorted_corpus_words]\n",
    "counts = [x[1] for x in sorted_corpus_words]\n",
    "\n",
    "#print tokens, values (logspace(-0.5, log10(len(counts)), 20).astype(int))\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "#Plot bar with values from dict and label with keys\n",
    "plt.bar(range(len(sorted_corpus_words)), counts, width=0.3)\n",
    "plt.xticks(range(len(sorted_corpus_words)), tokens)\n",
    "\n",
    "#Rotate labels by 90 degrees so you can see them\n",
    "locs, tokens = plt.xticks()\n",
    "plt.setp(tokens, rotation=90,fontsize=6)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) What is the 25th most common word in the corpus? How many times does it occur? What about the 50th most common word, the 100th and the 1000th?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_25 = corpus_words.most_common(25)[-1]\n",
    "most_common_50 = corpus_words.most_common(50)[-1]\n",
    "most_common_100 = corpus_words.most_common(100)[-1]\n",
    "\n",
    "print \"The 25th most common word: \\n\", most_common_25\n",
    "print \"\\nThe 50th most common word: \\n\", most_common_50\n",
    "print \"\\nThe 100th most common word: \\n\", most_common_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) How many different Part-of-speech tags are present in the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of distinct pos: \", len(distinct_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Print a list of the 10 most common part-of-speech tags. Spend a few minutes trying to guess what each tag means, by looking at associated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_pos = Counter(pos)\n",
    "\n",
    "most_common_10 = corpus_pos.most_common(10)\n",
    "\n",
    "print \"The 25th most common word: \\n\", most_common_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Assume that the probability $P(w_1^n)$ of a sentence $w_1 \\ldots w_n$   can be calculated as follows:\n",
    "\n",
    "$$P(w_1^n) = P(w_1) \\cdot P(w_2) \\ldots P(w_n) $$\n",
    "\n",
    "The probability of a word $w_i$ can be calculated from a corpus as \n",
    "$$P(w_i) = \\frac{count (w_i)}{N}$$ where $N$ is the total number of word tokens in the corpus. \n",
    "\n",
    "What is the probability of the first two sentences in the corpus? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import functools\n",
    "\n",
    "#Function to measure the probability of a uni-gram (w) in a corpus of total count N\n",
    "def get_word_probability(corpus, w):\n",
    "    #print corpus[w]\n",
    "    #print N\n",
    "    prob_w = (100.0 * float(corpus[w])) / (100 * float(len(corpus)))\n",
    "    return prob_w\n",
    "\n",
    "#Function to measure the probabilities of each word in a sentence and \n",
    "# the total probability of an n-gram sentence (s) in the corpus\n",
    "\n",
    "def get_sentence_probability(corpus,sentence):\n",
    "    #Probabilities of a sentence\n",
    "    probs_of_s = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        print word\n",
    "        probs_of_s.append(get_word_probability(corpus,word))\n",
    "    \n",
    "    total_prob_s = functools.reduce(operator.mul, probs_of_s, 1)\n",
    "    \n",
    "    return probs_of_s, total_prob_s\n",
    "                          \n",
    "print \"For the word the \", get_word_probability(corpus_words,'Inc.')\n",
    "\n",
    "# If you wanna take the first 2 sentences, then un-comment the for loop underneath. \n",
    "\n",
    "# Probability of the first two sentences in the corpus\n",
    "# enum = 0\n",
    "# for sentence in clear_sentences:\n",
    "#     if enum < 3:\n",
    "#         prob_of_s, total = get_sentence_probability(corpus_words,sentence)\n",
    "#         print prob_of_s, total\n",
    "#         enum += 1\n",
    "#     else:\n",
    "#         continue\n",
    "# print clear_sentences[1]\n",
    "\n",
    "x, y = get_sentence_probability(corpus_words, clear_sentences[2])\n",
    "print \"The probabilities of all words in the sentence is : \\n\", x\n",
    "print \"\\n\"\n",
    "print \"The total probability of the sentence is : \", y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) A word may have several part-of-speech tags, for example the word 'record' can be a noun or a verb. How many words do have more than one POS tag? What are the 10 most frequent combinations of POS tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are also provided with another file called **sec00.gold.tagged**. \n",
    "Section 00 of the Penn Treebank is typically used as development data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) How many unseen words are present in the development data (i.e., words that have not occurred in the training data)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What are the three most common kind of unseen word (their POS tags)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
